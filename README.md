```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â• â•šâ•â•â•â•â•â•
```

<p align="center">
  <b>UFDR Forensic Investigation Platform â€” Hybrid Search & AI-Powered Analysis</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="MIT License">
  <img src="https://img.shields.io/badge/Python-3.11+-yellow.svg" alt="Python 3.11+">
  <img src="https://img.shields.io/badge/Database-PostgreSQL-lightblue.svg" alt="Postgres">
  <img src="https://img.shields.io/badge/Search-OpenSearch-orange.svg" alt="OpenSearch">
  <img src="https://img.shields.io/badge/AI-SentenceTransformers-green.svg" alt="SentenceTransformers">
  <img src="https://img.shields.io/badge/Vector-FAISS-red.svg" alt="FAISS">
</p>

---

# ğŸ” ForensiQ â€” UFDR Forensic Investigation Platform

**ForensiQ** is an advanced, offline-capable forensic investigation system for **Cellebrite UFDR (Universal Forensic Data Report)** files.  
It empowers investigators with **hybrid search, entity extraction, and AI-powered analysis** while ensuring **data privacy and legal compliance**.

---

## âœ¨ Features

### ğŸ—‚ï¸ Phase 1 â€” Ingest & Parsing

- Parse Cellebrite UFDR ZIP archives
- Extract **messages** (SMS, chats, emails) with metadata
- Parse **contacts & call history**
- Catalog **attachments & media**
- Export structured **JSONL** for downstream processing

### ğŸ’¾ Phase 2 â€” Storage & Indexing

- Store data in **PostgreSQL** (or SQLite for demo) with SQLAlchemy ORM
- Index messages in **OpenSearch** for full-text search
- Robust ETL with **idempotent upserts**
- Integrity checks & error handling

### ğŸ§  Phase 3 â€” NLP & Entity Extraction

- Detect **phone numbers, emails, URLs, crypto addresses**
- Normalize phones into **E.164 international format**
- Generate **semantic embeddings** using sentence-transformers
- Build **FAISS index** for similarity search

### ğŸ” Phase 4 â€” Hybrid Retrieval & Summarization

- Combine **keyword search (OpenSearch)** + **semantic search (FAISS)**
- Provide **FastAPI REST API** for querying evidence
- Local **summarization** with HuggingFace (BART/T5)  
- Score fusion & relevance ranking

### ğŸ–¥ï¸ Phase 5 â€” Web Interface

- **React + TypeScript** investigator dashboard
- **Interactive search** with entity highlighting
- **Network graph visualization** of relationships
- **Export capabilities** (PDF, HTML, JSON)
- **Responsive design** for all devices

---

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.11+
- Node.js 16+ (for frontend)
- PostgreSQL (optional, SQLite fallback works)
- OpenSearch (for keyword search)
- FAISS (CPU or GPU)

### Quick Setup

```bash
# Clone repo
git clone https://github.com/Av7danger/ForensiQ.git
cd ForensiQ

# Backend setup
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
python -c "from backend.db import init_db; init_db()"

# Frontend setup
cd frontend
npm install
npm run dev
```

### Core Dependencies

```bash
# Database & ETL
pip install sqlalchemy psycopg2-binary opensearch-py python-dotenv

# NLP & embeddings
pip install sentence-transformers faiss-cpu phonenumbers transformers

# API
pip install fastapi uvicorn pydantic

# Optional (GPU acceleration)
pip install faiss-gpu torch
```

---

## ğŸ“– Usage

### 1ï¸âƒ£ Parse UFDR Files

```bash
python parsers/ufdr_parser.py --input case.ufdr --output ./output/CASE-001/
```

### 2ï¸âƒ£ Load Data into DB

```bash
python backend/etl_load.py --input ./output/CASE-001/parsed/ --case CASE-001
```

### 3ï¸âƒ£ Build Search Indexes

```bash
# Keyword search (OpenSearch)
python backend/opensearch_index.py --input ./output/CASE-001/parsed/messages.jsonl --index messages

# Semantic search (FAISS)
python nlp/embeddings_worker.py --input ./output/CASE-001/parsed/messages.jsonl --out ./vectors/
```

### 4ï¸âƒ£ Start Services

```bash
# Backend API
uvicorn backend.app.query:app --reload --host 0.0.0.0 --port 8000

# Frontend (new terminal)
cd frontend && npm run dev
```

### 5ï¸âƒ£ Access Interface

- **Web Dashboard**: http://localhost:5173
- **API Documentation**: http://localhost:8000/docs

### 6ï¸âƒ£ Run a Query

```bash
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{
    "q": "suspicious cryptocurrency transactions",
    "limit": 5,
    "page": 1
  }'
```

---

## ğŸ—ï¸ Architecture

```
ForensiQ/
â”œâ”€â”€ parsers/        # Phase 1: UFDR parsing
â”œâ”€â”€ backend/        # Phase 2: DB, indexing, API
â”œâ”€â”€ nlp/            # Phase 3: Entity extraction & embeddings
â”œâ”€â”€ frontend/       # Phase 5: React dashboard
â”œâ”€â”€ vectors/        # FAISS index
â””â”€â”€ output/         # Parsed case data
```

**Data Flow:**

1. **UFDR â†’ Parser â†’ JSONL**
2. **JSONL â†’ ETL â†’ PostgreSQL**
3. **Messages â†’ OpenSearch (keywords)**
4. **Messages â†’ NLP â†’ FAISS (embeddings)**
5. **Query â†’ Hybrid Retrieval â†’ Web Interface â†’ Results**

---

## ğŸ” Search Modes

### Keyword Search (OpenSearch)

* Exact / fuzzy search
* Field-specific (sender, recipient, body)
* Boolean queries

### Semantic Search (FAISS)

* Conceptual similarity
* Context-aware results
* Cross-lingual support

### Hybrid Fusion

* Weighted score combination
* Deduplication & boosting
* Optimized ranking

---

## ğŸ¤– AI Features

* **Entity Extraction**: Phones, emails, URLs, crypto
* **Phone Normalization**: International (E.164)
* **Summarization**: Local HuggingFace models
* **Privacy First**: No external API calls

---

## ğŸ“Š API Reference

### POST `/api/search`

Hybrid search with pagination.

**Request**

```json
{
  "q": "search query",
  "limit": 10,
  "page": 1,
  "type": "messages"
}
```

**Response**

```json
{
  "results": [
    {
      "id": "msg_123",
      "type": "message",
      "content": "Message text...",
      "score": 0.92,
      "entities": {
        "phones": ["+15551234567"],
        "emails": ["user@example.com"]
      },
      "timestamp": "2024-01-15T10:30:00Z"
    }
  ],
  "total": 42,
  "page": 1,
  "per_page": 10
}
```

### GET `/api/evidence/{id}`

Get detailed evidence information.

### GET `/api/graph`

Get network graph data for visualization.

### GET `/health`

Simple health check.

---

## âš™ï¸ Configuration

Set environment variables in `.env`:

```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/ufdr

# Search
OPENSEARCH_URL=http://localhost:9200
FAISS_INDEX_DIR=./vectors

# Models
EMBEDDING_MODEL=all-MiniLM-L6-v2

# API
API_HOST=0.0.0.0
API_PORT=8000
```

Frontend configuration in `frontend/.env.local`:

```bash
VITE_API_BASE_URL=http://localhost:8000
VITE_APP_TITLE=ForensiQ Investigator Dashboard
```

---

## ğŸš§ Roadmap

* [x] ~~UFDR parsing & data extraction~~
* [x] ~~Hybrid search (keyword + semantic)~~
* [x] ~~Entity extraction & phone normalization~~
* [x] ~~REST API with FastAPI~~
* [x] ~~React investigator dashboard~~
* [x] ~~Network graph visualization~~
* [ ] File upload interface
* [ ] Timeline analysis view
* [ ] Advanced case management
* [ ] Multi-case correlation
* [ ] Docker & K8s deployment

---

## ğŸ”’ Security & Privacy

* 100% **offline-capable**
* **No external APIs**
* Local processing of sensitive forensic data
* Audit logs for legal compliance
* Secure file handling with integrity checks

---

## ğŸ§ª Testing

Run the test suite:

```bash
# Backend tests
python -m pytest tests/

# Entity extraction test
python -c "
from nlp.extractors import extract_entities
result = extract_entities('Call +1-555-123-4567')
assert result['phones']
print('âœ… Entity extraction: PASS')
"

# Phone normalization test  
python -c "
from nlp.normalize_phone import normalize_phone
assert normalize_phone('(555) 123-4567') == '+15551234567'
print('âœ… Phone normalization: PASS')
"

# Frontend tests
cd frontend && npm test
```

---

## ğŸ“ License

MIT License â€” see [LICENSE](LICENSE)

---

## ğŸ¤ Contributing

1. Fork repo
2. Create feature branch (`git checkout -b feature/my-feature`)
3. Commit changes (`git commit -m 'Add feature'`)
4. Push (`git push origin feature/my-feature`)
5. Open PR

---

## ğŸ“š Documentation

* [Setup Instructions](SETUP.md) - Complete installation guide
* [Parser Docs](parsers/README.md) - UFDR parsing details
* [Backend API Guide](backend/README.md) - API documentation
* [Frontend Guide](frontend/README.md) - Web interface setup
* [NLP Module](nlp/README.md) - Entity extraction & embeddings

---

## ğŸ† Acknowledgments

* **Cellebrite** for UFDR specs
* **HuggingFace** for NLP models
* **OpenSearch** community
* **FAISS** team
* **React** & **TypeScript** communities

---

ğŸš€ **ForensiQ** â€” Empowering forensic investigators with **offline, AI-powered evidence analysis**.